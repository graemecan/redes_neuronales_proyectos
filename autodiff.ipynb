{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd5e446",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d80c5a",
   "metadata": {},
   "source": [
    "Supongamos que queremos calcular los gradientes de la función $f(x,y) = x^2y+y+2$ con respecto a los argumentos $x$ y $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317e5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda545bc",
   "metadata": {},
   "source": [
    "Una opción es obtener las derivadas analíticamente:\n",
    "\n",
    "$\\frac{\\partial f}{\\partial x} = 2xy$\n",
    "\n",
    "$\\frac{\\partial f}{\\partial y} = x^2 + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a7dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(x,y):\n",
    "    return 2*x*y, x*x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e2d65",
   "metadata": {},
   "source": [
    "Por ejemplo, $\\frac{\\partial f}{\\partial x}(3,4) = 24$ y $\\frac{\\partial f}{\\partial y}(3,4) = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762878dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288b49b",
   "metadata": {},
   "source": [
    "También podemos obtener las ecuaciones para las segundas derivadas (*hessianas*):\n",
    "\n",
    "$\\dfrac{\\partial^2 f}{\\partial x \\partial x} = \\dfrac{\\partial (2xy)}{\\partial x} = 2y$\n",
    "\n",
    "$\\dfrac{\\partial^2 f}{\\partial x \\partial y} = \\dfrac{\\partial (2xy)}{\\partial y} = 2x$\n",
    "\n",
    "$\\dfrac{\\partial^2 f}{\\partial y \\partial x} = \\dfrac{\\partial (x^2 + 1)}{\\partial x} = 2x$\n",
    "\n",
    "$\\dfrac{\\partial^2 f}{\\partial y \\partial y} = \\dfrac{\\partial (x^2 + 1)}{\\partial y} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17df19f",
   "metadata": {},
   "source": [
    "En $x=3$ y $y=4$ estas hessianas son respectivamente $8$, $6$, $6$, $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0445ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2f(x, y):\n",
    "    return [2*y, 2*x], [2*x, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77247cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([8, 6], [6, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2f(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4767fba",
   "metadata": {},
   "source": [
    "Para una red neuronal profunda (con muchas capas) es imposible evaluar las derivadas en esta manera. Vamos a buscar como automatizar este proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db187c6b",
   "metadata": {},
   "source": [
    "# Derivación numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbcbcf",
   "metadata": {},
   "source": [
    "Diferencias finítas: aproximamos los gradientes usando la definición de la derivada\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = \\lim_{\\epsilon \\to 0} \\frac{f(x+\\epsilon,y) - f(x,y)}{\\epsilon}$$ \n",
    "\n",
    "Hay una definición similar para $\\partial f/\\partial y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc74a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientes(func, vars_lista, eps=0.0001):\n",
    "    derivadas_parciales = []\n",
    "    func_eval = func(*vars_lista)\n",
    "    for idx in range(len(vars_lista)):\n",
    "        vars_epsilon = vars_lista[:]\n",
    "        vars_epsilon[idx] += eps\n",
    "        func_eval_epsilon = func(*vars_epsilon)\n",
    "        derivada = (func_eval_epsilon - func_eval) / eps\n",
    "        derivadas_parciales.append(derivada)\n",
    "    return derivadas_parciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adb0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(x, y):\n",
    "    return gradientes(f, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9233af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.000400000048216, 10.000000000047748]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f87d9d",
   "metadata": {},
   "source": [
    "Ahora, calculamos los elementos del jacobiano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c2797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfdx(x, y):\n",
    "    return gradientes(f, [x,y])[0]\n",
    "\n",
    "def dfdy(x, y):\n",
    "    return gradientes(f, [x,y])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b46156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.000400000048216, 10.000000000047748)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdx(3., 4.), dfdy(3., 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e29c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2f(x, y):\n",
    "    return [gradientes(dfdx, [x, y]), gradientes(dfdy, [x, y])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9e3f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.999999951380232, 6.000099261882497],\n",
       " [6.000099261882497, -1.4210854715202004e-06]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2f(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c14e1",
   "metadata": {},
   "source": [
    "Funciona, pero con aproximaciones. Además, para calcular los gradientes de una función con respecto a $n$ variables requiere $n$ evaluaciones de dicha función. En redes neuronales profundas hay miles de parámetros, así que este método es demasiado lento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb73172",
   "metadata": {},
   "source": [
    "# Implementación de un gráfo computacional (de juguete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26dbec",
   "metadata": {},
   "source": [
    "Ahora vamos a definir nuestro propio código para implementar el procedimiento de AutoDiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d7c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const(): # Suponiendo Python 3!!\n",
    "    def __init__(self, valor):\n",
    "        self.valor = valor\n",
    "    def evaluar(self):\n",
    "        return self.valor\n",
    "    def __str__(self):\n",
    "        return str(self.valor)\n",
    "    \n",
    "class Var():\n",
    "    def __init__(self, nombre, ini_valor=0):\n",
    "        self.valor = ini_valor\n",
    "        self.nombre = nombre\n",
    "    def evaluar(self):\n",
    "        return self.valor\n",
    "    def __str__(self):\n",
    "        return self.nombre\n",
    "    \n",
    "class OperadorBinario():\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "class Suma(OperadorBinario):\n",
    "    def evaluar(self):\n",
    "        return self.a.evaluar() + self.b.evaluar()\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "    \n",
    "class Prod(OperadorBinario):\n",
    "    def evaluar(self):\n",
    "        return self.a.evaluar() * self.b.evaluar()\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9b5f6",
   "metadata": {},
   "source": [
    "Ahora podemos contruir un gráfo computacional para representar la función $f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cfa18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Var(\"x\")\n",
    "y = Var(\"y\")\n",
    "f = Suma(Prod(Prod(x, x), y), Suma(y, Const(2))) # f(x,y) = x^2 y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75dbd04",
   "metadata": {},
   "source": [
    "Podemos \"ejecutar\" el gráfo para calcular $f$ en cualquier punto, por ejemplo $f(3,4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9227ffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.valor = 3\n",
    "y.valor = 4\n",
    "f.evaluar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da147f",
   "metadata": {},
   "source": [
    "# Calculando gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b981946",
   "metadata": {},
   "source": [
    "Los métodos de AutoDiff que veremos abajo están todos basados en la *regla de cadena*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0152e",
   "metadata": {},
   "source": [
    "Supongamos que tenemos dos funciones $u$ y $v$, y las aplicamos secuencialmente a una entrada $x$, para obtener el resultado $z$. Entonces, $z = v(u(x))$. Podemos escribir esta composición de funciones así:\n",
    "\n",
    "$$z = v(s) \\quad \\quad s = u(x)$$\n",
    "\n",
    "Ahora, podemos aplicar la regla de cadena para obtener la derivada de $z$ con respecto a $x$:\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial x} = \\frac{\\partial s}{\\partial x} \\cdot \\frac{\\partial z}{\\partial s}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e47526",
   "metadata": {},
   "source": [
    "Se puede generalizar este resultado inmediatemente al caso de tener una secuencia de $n$ funciones: $s_1,s_2,\\ldots,s_n$:\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial x} = \\frac{\\partial s_1}{\\partial x} \\cdot \\frac{\\partial s_2}{\\partial s_1} \\cdot \\frac{\\partial s_3}{\\partial s_2} \\cdot \\cdots \\cdot \\frac{\\partial s_{n-1}}{\\partial s_{n-2}} \\cdot \\frac{\\partial s_n}{\\partial s_{n-1}} \\cdot \\frac{\\partial z}{\\partial s_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8af14",
   "metadata": {},
   "source": [
    "En modo hacia adelante de AutoDiff (*forward mode*) el algoritmo calcula estos términos en el mismo orden en que están escritos arriba, de la izquierda hacia la derecha, comenzando con $\\partial s_1/\\partial x$.\n",
    "\n",
    "En modo hacia atrás (*reverse mode*) el algoritmo va de la derecha hacia la izquierda. Es decir, comienza con $\\partial z/\\partial s_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad723f8",
   "metadata": {},
   "source": [
    "### Ejemplo (*forward mode*)\n",
    "\n",
    "Queremos calcular la derivada de la función\n",
    "\n",
    "$$z(x) = \\sin(x^2)$$\n",
    "\n",
    "en el punto $x = 3$ ocupando AutoDiff en modo hacia adelante. El algoritmo calculará primero la derivada\n",
    "\n",
    "$$\\frac{\\partial s_1}{\\partial x} = \\frac{\\partial x^2}{\\partial x} = 2x = 6$$\n",
    "\n",
    "Después calculará\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial x} = \\frac{\\partial s_1}{\\partial x} \\cdot \\frac{\\partial z}{\\partial s_1} = 6 \\cdot \\frac{\\partial \\sin(s_1)}{\\partial s_1} = 6 \\cdot \\cos(s_1) = 6 \\cdot \\cos(3^2) \\approx -5.46$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f0b64",
   "metadata": {},
   "source": [
    "Verificamos este resultado usando la función `gradientes()` que vimos antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c343bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "\n",
    "def z(x):\n",
    "    return sin(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acea2f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5.46761419430053]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientes(z, [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447cb1a",
   "metadata": {},
   "source": [
    "### Ejemplo (*reverse mode*)\n",
    "\n",
    "Ahora hacemos lo mismo con AutoDiff hacia atrás. El algoritmo calculará\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial s_1} = \\frac{\\partial \\sin(s_1)}{\\partial s_1} = \\cos(s_1) = \\cos(3^2) \\approx -0.91$$\n",
    "\n",
    "Después calculará\n",
    "\n",
    "$$\\frac{\\partial z}{\\partial x} = \\frac{\\partial s_1}{\\partial x} \\cdot \\frac{\\partial z}{\\partial s_1} \\approx \\frac{\\partial s_1}{\\partial x} \\cdot -0.91 = \\frac{\\partial x^2}{\\partial x} \\cdot -0.91 = 2x \\cdot -0.91 = 6 \\cdot -0.91 = -5.46$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc00a0d",
   "metadata": {},
   "source": [
    "Con una sola entrada y salida, ambos métodos requieren el mismo número de cálculaciones. Pero en el caso de tener varias entradas y salidas, los dos modos pueden deferir muchísimo en su rendimiento.\n",
    "\n",
    "En el caso de tener muchas entradas, los términos hacia la derecha son requeridos para calcular las derivadas con respecto a cada entrada. Por lo tanto es mejor calcular esas derivadas primero (*reverse mode*). Así podemos calcular los términos a la derecha una sóla vez y usarlos para calcular todas las derivadas parciales.\n",
    "\n",
    "En el caso de tener muchas salids, se puede calcular los términos a la izquierda primero, y usarlos para calcular las derivadas parciales con respecto a las salidas. Este corresponde a *forward mode*.\n",
    "\n",
    "En *deep learning* hay miles de parámetros (las entradas del algoritmo) y pocas salidas. De hecho, típicamente hay una sola salida: el valor de la función de coste!\n",
    "\n",
    "Por tal razón, el modo hacia atrás (*reverse mode*) es usado en TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70662040",
   "metadata": {},
   "source": [
    "#### Pase hacia adelante primero\n",
    "\n",
    "Hay un detalle con respecto a AutoDiff con *reverse mode*. Para calcular $\\partial s_{i+1}/\\partial s_i$ necesitamos el valor de $s_i$, pero para calcular $s_i$ necesitamos $s_{i-1}$, que requiere $s_{i-1}$, etc.\n",
    "\n",
    "Por lo tanto, necesitamos una primera pase por la red hacia adelante para calcular y guardar los valores de $s_1,s_2,s_3,\\ldots,s_{n}$. A veces este es problemático para el RAM..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7fcd26",
   "metadata": {},
   "source": [
    "## AutoDiff modo hacia adelante (*forward mode*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa59c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Const.gradiente = lambda self, var: Const(0)\n",
    "Var.gradiente = lambda self, var: Const(1) if self is var else Const(0)\n",
    "Suma.gradiente = lambda self, var: Suma(self.a.gradiente(var), self.b.gradiente(var))\n",
    "Prod.gradiente = lambda self, var: Suma(Prod(self.a, self.b.gradiente(var)), Prod(self.a.gradiente(var), self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c6e45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Var(nombre=\"x\", ini_valor=3.)\n",
    "y = Var(nombre=\"y\", ini_valor=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc40c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Suma(Prod(Prod(x, x), y), Suma(y, Const(2))) # f(x,y) = x^2y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5529066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx = f.gradiente(x) # 2xy\n",
    "dfdy = f.gradiente(y) #x^2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a21158d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.0, 10.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdx.evaluar(), dfdy.evaluar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1024a",
   "metadata": {},
   "source": [
    "Ya que la salida del método `gradiente()` es totalmente simbólica, podemos calcular derivadas de cualquier orden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2fdxdx = dfdx.gradiente(x) #2y\n",
    "d2fdxdy = dfdx.gradiente(y) #2x\n",
    "d2fdydx = dfdy.gradiente(x) #2x\n",
    "d2fdydy = dfdy.gradiente(y) #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0be03ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8.0, 6.0], [6.0, 0.0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[d2fdxdx.evaluar(), d2fdxdy.evaluar()],\n",
    " [d2fdydx.evaluar(), d2fdydy.evaluar()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ce31b",
   "metadata": {},
   "source": [
    "El resultado es exacto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1372388",
   "metadata": {},
   "source": [
    "## AutoDiff de *forward mode* con números duales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fd35e",
   "metadata": {},
   "source": [
    "Otra forma de implementar el algoritmo es con números duales. Tiene la forma $z = a+b\\epsilon$ donde $a$ y $b$ son números reales y $\\epsilon$ es un número positivo infinitesimal, más pequeño que cualquier otro número, tal que $\\epsilon^2 = 0$.\n",
    "\n",
    "Por el teorema de Taylor, tenemos\n",
    "\n",
    "$$f(x+\\epsilon) = f(x) + \\frac{df}{dx}\\epsilon$$\n",
    "\n",
    "Así que calculando $f(x+\\epsilon)$ obtenemos $f(x)$ y su derivada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1103edb",
   "metadata": {},
   "source": [
    "Reglas aritméticas de números duales:\n",
    "\n",
    "**Suma**\n",
    "\n",
    "$$(a_1+b_1\\epsilon) + (a_2+b_2\\epsilon) = (a_1 + a_2) + (b_1+b_2)\\epsilon$$\n",
    "\n",
    "**Resta**\n",
    "\n",
    "$$(a_1+b_1\\epsilon) - (a_2+b_2\\epsilon) = (a_1 - a_2) + (b_1-b_2)\\epsilon$$\n",
    "\n",
    "**Producto**\n",
    "\n",
    "$$(a_1+b_1\\epsilon) \\times (a_2+b_2\\epsilon) = (a_1a_2) + (a_1b_2+a_2b_1)\\epsilon + b_1b_2\\epsilon^2 = (a_1a_2) + (a_1b_2+a_2b_1)\\epsilon$$\n",
    "\n",
    "**División**\n",
    "\n",
    "$$\\frac{a_1+b_1\\epsilon}{a_2+b_2\\epsilon} = \\frac{a_1+b_1\\epsilon}{a_2+b_2\\epsilon} \\cdot \\frac{a_2-b_2\\epsilon}{a_2-b_2\\epsilon} = \\frac{a_1a_2 + (b_1a_2-a_1b_2)\\epsilon - b_1b_2\\epsilon^2}{a_2^2 + (a_2b_2-a_2b_2)\\epsilon - b_2^2\\epsilon} = \\frac{a_1}{a_2} + \\frac{a_1b_2-b_1a_2}{a_2^2}\\epsilon$$\n",
    "\n",
    "**Potencia**\n",
    "\n",
    "$$(a+b\\epsilon)^n = a^n + (na^{n-1}b)\\epsilon$$\n",
    "\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e2a3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumeroDual(object):\n",
    "    def __init__(self, valor=0.0, eps=0.0):\n",
    "        self.valor = valor\n",
    "        self.eps = eps\n",
    "    def __add__(self, b):\n",
    "        return NumeroDual(self.valor + self.to_dual(b).valor,\n",
    "                          self.eps + self.to_dual(b).eps)\n",
    "    def __radd__(self, a):\n",
    "        return self.to_dual(a).__add__(self)\n",
    "    def __mul__(self, b):\n",
    "        return NumeroDual(self.valor * self.to_dual(b).valor,\n",
    "                          self.eps * self.to_dual(b).valor + self.valor * self.to_dual(b).eps)\n",
    "    def __rmul__(self, a):\n",
    "        return self.to_dual(a).__mul__(self)\n",
    "    def __str__(self):\n",
    "        if self.eps:\n",
    "            return \"{:.1f} + {:.1f}ε\".format(self.valor, self.eps)\n",
    "        else:\n",
    "            return \"{:.1f}\".format(self.valor)\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    @classmethod\n",
    "    def to_dual(cls, n):\n",
    "        if hasattr(n, \"valor\"):\n",
    "            return n\n",
    "        else:\n",
    "            return cls(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a6f6c",
   "metadata": {},
   "source": [
    "$3 + (3+4\\epsilon) = 6+4\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50033cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0 + 4.0ε"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + NumeroDual(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ccd7dd",
   "metadata": {},
   "source": [
    "$(3 + 4ε)\\times(5 + 7ε)$ = $3 \\times 5 + 3 \\times 7ε + 4ε \\times 5 + 4ε \\times 7ε$ = $15 + 21ε + 20ε + 28ε^2$ = $15 + 41ε + 28 \\times 0$ = $15 + 41ε$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b05a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0 + 41.0ε"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumeroDual(3, 4) * NumeroDual(5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bf47449",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.valor = NumeroDual(3.0)\n",
    "y.valor = NumeroDual(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed63c1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.evaluar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f0b8a",
   "metadata": {},
   "source": [
    "La clase para número duales funciona sin problemas con la clase del gráfo computacional.\n",
    "\n",
    "Ahora, calculamos las derivadas parciales de $f$ con respecto a $x$ y $y$ en $x=3$, $y=4$ usando los numeros duales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf2b3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.valor = NumeroDual(3.0, 1.0) #3 + ε\n",
    "y.valor = NumeroDual(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b126845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdx = f.evaluar().eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c3d9d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dd08fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.valor = NumeroDual(3.0) #3\n",
    "y.valor = NumeroDual(4.0, 1.0) # 4 + ε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75bba73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdy = f.evaluar().eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea218bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52e462",
   "metadata": {},
   "source": [
    "En nuestra implementación estamos limitados a derivadas de primer orden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dd57e",
   "metadata": {},
   "source": [
    "## AutoDiff hacia atrás (*reverse mode*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8461c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const():\n",
    "    def __init__(self, valor):\n",
    "        self.valor = valor\n",
    "    def evaluar(self):\n",
    "        return self.valor\n",
    "    def backpropagate(self, gradiente):\n",
    "        pass\n",
    "    def __str__(self):\n",
    "        return str(self.valor)\n",
    "    \n",
    "class Var():\n",
    "    def __init__(self, nombre, ini_valor=0):\n",
    "        self.valor = ini_valor\n",
    "        self.nombre = nombre\n",
    "        self.gradiente = 0\n",
    "    def evaluar(self):\n",
    "        return self.valor\n",
    "    def backpropagate(self, gradiente):\n",
    "        self.gradiente += gradiente\n",
    "    def __str__(self):\n",
    "        return self.nombre\n",
    "    \n",
    "class OperadorBinario():\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "class Suma(OperadorBinario):\n",
    "    def evaluar(self):\n",
    "        self.valor = self.a.evaluar() + self.b.evaluar()\n",
    "        return self.valor\n",
    "    def backpropagate(self, gradiente):\n",
    "        self.a.backpropagate(gradiente)\n",
    "        self.b.backpropagate(gradiente)\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "    \n",
    "class Prod(OperadorBinario):\n",
    "    def evaluar(self):\n",
    "        self.valor = self.a.evaluar() * self.b.evaluar()\n",
    "        return self.valor\n",
    "    def backpropagate(self, gradiente):\n",
    "        self.a.backpropagate(gradiente * self.b.valor)\n",
    "        self.b.backpropagate(gradiente * self.a.valor)\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "626f8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Var(\"x\", ini_valor=3)\n",
    "y = Var(\"y\", ini_valor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18ce7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Suma(Prod(Prod(x, x), y), Suma(y, Const(2))) #f(x,y) = x^2y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6241d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = f.evaluar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c691576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backpropagate(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e79e3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((x) * (x)) * (y) + y + 2\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95652332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8210ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9021bb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e87e43",
   "metadata": {},
   "source": [
    "En este implementación las salidas son números, no expresiones simbólicas, así que no podemos obtener derivadas de mayor orden.\n",
    "\n",
    "Podríamos modificar los métodos de `backpropagate()` para devolver expresiones simbólicas en vez de valores (por ejemplo `return Suma(2,3)` en vez de `5`). Con eso sería posible calcular derivadas de cualquier orden.\n",
    "\n",
    "TensorFlow hace exactamente eso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab647ef",
   "metadata": {},
   "source": [
    "## AutoDiff de *reverse mode* con TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bfe4004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 15:37:04.309064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 15:37:12.646669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77feb7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 15:37:20.516286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 15:37:20.832173: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.)\n",
    "y = tf.Variable(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a4e2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdc3e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobianos = tape.gradient(f, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf7b706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=24.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobianos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc1f55",
   "metadata": {},
   "source": [
    "Podemos calcular derivadas de cualquier orden, porque todo es simbólico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fd0af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.)\n",
    "y = tf.Variable(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c318a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    f = x*x*y + y + 2\n",
    "    df_dx, df_dy = tape.gradient(f, [x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25ba9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2f_d2x, d2f_dydx = tape.gradient(df_dx, [x, y])\n",
    "d2f_dxdy, d2f_d2y = tape.gradient(df_dy, [x, y])\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "561967e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessianos = [[d2f_d2x, d2f_dydx], [d2f_dxdy, d2f_d2y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d90b4e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=6.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, None]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessianos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de1264",
   "metadata": {},
   "source": [
    "Notar aquí que la última derivada $\\partial^2 f/\\partial y^2 = 0$. En TensorFlow esta valor está representado por `None`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
