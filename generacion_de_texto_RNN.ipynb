{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216490b2",
   "metadata": {},
   "source": [
    "# Generación de texto con una red recurrente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a164c12",
   "metadata": {},
   "source": [
    "* El ejemplo ocupa texto de Shakespeare\n",
    "* Podríamos repetir el proceso con Cervantes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3c905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:02:59.027077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067610a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_al_archivo = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12cad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = open(ruta_al_archivo, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5be6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 1115394 carácteres\n"
     ]
    }
   ],
   "source": [
    "print(f'Longitud del texto: {len(texto)} carácteres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6f1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texto[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c693d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7044f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 carácteres únicos\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(vocab)} carácteres únicos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9c4eb",
   "metadata": {},
   "source": [
    "## Vectorización del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd2121",
   "metadata": {},
   "source": [
    "Antes de entrenar el modelo, necesitamos convertir los *strings* a una representación numérica.\n",
    "\n",
    "La capa `tf.keras.layers.StringLookup` puede convertir cada carácter en un ID numérico. Necesita que el texto esté separado en fichas (*tokens*) primero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53456859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:03:11.588264: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "ejemplos = ['abcdefg', 'xyz']\n",
    "\n",
    "caracteres = tf.strings.unicode_split(ejemplos, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d998a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6024266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_de_cars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6280373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_de_cars(caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccbe4700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3bced",
   "metadata": {},
   "source": [
    "Podemos invertir la representación numérica para extraer carácteres de nuevo. (Usamos un método `get_vocabulary` de la capa `StringLookup` para obtener el vocabulario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db920e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_de_ids = tf.keras.layers.StringLookup(vocabulary=ids_de_cars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0f3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars_de_ids(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f54c6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27794174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(cars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4267954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_de_ids(ids):\n",
    "    return tf.strings.reduce_join(cars_de_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708119f",
   "metadata": {},
   "source": [
    "### La tarea de predicción\n",
    "\n",
    "Dado un carácter, o una secuencia de carácteres, cuál carácter es el más probable que viene después? Vamos a entrenar el modelo para resolver este problema.\n",
    "\n",
    "La entrada es una secuencia de carácteres (en su representación numérica) y la predicción será el próximo carácter en cada paso del tiempo.\n",
    "\n",
    "Las redes recurrentes mantienen un estado interno que depende de los elementos vistos previamente. Así que, la pregunta es: dado todos los carácteres obtenidos hasta este momento, cuál es el próximo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48024fb",
   "metadata": {},
   "source": [
    "### Crear ejemplos de entrenamiento y objetivos\n",
    "\n",
    "Dividimos el texto en secuencias de ejemplo. Cada secuencia de entrada contendrá `longitud_sec` carácteres del texto.\n",
    "\n",
    "Para cada secuencia de entrada, los objetivos que corresponden contienen el mismo número de carácteres, pero desplazado un carácter a la derecha.\n",
    "\n",
    "Rompimos el texto en pedazos de `longitud_sec+1`. Por ejemplo, digamos que `longitud_sec` = 4, y nuestro texto es \"Hello\". La secuencia de entrada sería \"Hell\" y la secuencia de objetivo sería \"ello\".\n",
    "\n",
    "Ocupamos la función `tf.data.Dataset.from_tensor_slices` para convertir el vector de texto en una secuencia de indices de carácteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cff938f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_ids = ids_de_cars(tf.strings.unicode_split(texto, 'UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7df5ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d4b3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(todos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ef1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1b72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:03:53.697317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(cars_de_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10f6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud_sec = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b055af",
   "metadata": {},
   "source": [
    "El método `batch` facilita la conversión de carácteres individuales a secuencias del tamaño requerido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e19c80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "secuencias = ids_dataset.batch(longitud_sec+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6a6e3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:03:59.249081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for sec in secuencias.take(1):\n",
    "    print(cars_de_ids(sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ce1337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:04:03.810549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for sec in secuencias.take(5):\n",
    "    print(texto_de_ids(sec).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fd727",
   "metadata": {},
   "source": [
    "Para el entrenamiento necesitamos un dataset de pares de `(entrada, etiqueta)`, donde `entrada` y `etiqueta` son secuencias. En cada paso del tiempo la entrada es el carácter actual y la etiqueta es el carácter subsiguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50b6c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_entrada_objetivo(secuencia):\n",
    "    texto_entrada = secuencia[:-1]\n",
    "    texto_objetivo = secuencia[1:]\n",
    "    return texto_entrada, texto_objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "097c58b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'F', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'F', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dividir_entrada_objetivo(list(\"TensorFlow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31404e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = secuencias.map(dividir_entrada_objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b52ac2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79bf9ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:  b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Objetivo:  b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:04:16.748342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for ejemplo_entrada, ejemplo_objetivo in dataset.take(1):\n",
    "    print(\"Entrada: \", texto_de_ids(ejemplo_entrada).numpy())\n",
    "    print(\"Objetivo: \", texto_de_ids(ejemplo_objetivo).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a441d",
   "metadata": {},
   "source": [
    "### Crear lotes de entrenamiento\n",
    "\n",
    "Tenemos que barajar los datos y empacarlos en lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69a26e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de los lotes\n",
    "LOTE = 64\n",
    "\n",
    "# Tamaño del \"buffer\" para barajar los datos\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(LOTE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0e17775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3a251",
   "metadata": {},
   "source": [
    "## Construir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d40640",
   "metadata": {},
   "source": [
    "Vamos a usar el API de \"subclassing\" (en vez del API funcional que usabamos en la parte sobre redes de *feed-forward*).\n",
    "\n",
    "El modelo tiene 3 capas:\n",
    "\n",
    "* `tf.keras.layers.Embedding`: la capa de entrada. Una tabla de tipo \"lookup\" (entrenable) que va a mapear cada carácter-ID a un vector con dimensiones `embedding_dim`.\n",
    "<p> <br> </p>\n",
    "* `tf.keras.layers.GRU`: un tipo de RNN con tamaño `units=rnn_units` (también podríamos usar LSTM aquí)\n",
    "<p> <br> </p>\n",
    "* `tf.keras.layers.Dense`: la capa de salida, con `vocab_size` salidas. Produce un *logit* por cada carácter del vocabulario. Estos son los *log-likelihood* de cada carácter según el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b59d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ids_de_cars.get_vocabulary())\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4724e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiModelo(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4d69f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MiModelo(vocab_size=vocab_size, \n",
    "                  embedding_dim=embedding_dim, \n",
    "                  rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5436969",
   "metadata": {},
   "source": [
    "Un diagrama del modelo:\n",
    "\n",
    "![](text_generation_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db92dc",
   "metadata": {},
   "source": [
    "Primero, verificamos la forma de la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c90dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:04:32.704102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-25 10:04:32.704784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (lote, secuencia, vocabulario)\n"
     ]
    }
   ],
   "source": [
    "for lote_entrada_ejemplo, lote_objetivo_ejemplo in dataset.take(1):\n",
    "    lote_predicciones_ejemplo = modelo(lote_entrada_ejemplo)\n",
    "    print(lote_predicciones_ejemplo.shape, \"# (lote, secuencia, vocabulario)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7069cf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mi_modelo\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb6e2f",
   "metadata": {},
   "source": [
    "Para obtener predicciones del modelo, tenemos que extraer muestras de la distribución de salidas. Esta distribución se define por los *logits* sobre el vocabulario de carácteres.\n",
    "\n",
    "Si ocupamos simplemente `argmax` el modelo se puede congelar en un *loop* infinito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b57ecdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_muestra = tf.random.categorical(lote_predicciones_ejemplo[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9989c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_muestra = tf.squeeze(indices_muestra, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ac35143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 20, 14, 49, 16, 33,  8, 56, 62, 55, 43, 33,  9, 37, 59, 21, 62,\n",
       "        5, 43,  9, 23, 39, 62, 11, 18, 25, 16, 47, 43, 65, 25, 27, 40, 59,\n",
       "       27, 56, 34,  1,  4, 62, 59, 48, 42, 14, 60, 38, 44,  3, 43, 45, 33,\n",
       "       18, 25,  6, 27, 49, 35, 65,  4, 30, 25,  5,  5, 49, 44, 54,  1, 19,\n",
       "       49,  7, 60, 44, 45, 58, 10,  7, 62, 57, 59, 33, 45, 20, 63, 23, 13,\n",
       "       41, 64, 62, 10, 56, 18, 59, 34, 20, 15,  3, 33, 53, 24, 17])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0767cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:\n",
      " b\"ngerous unsafe lunes i' the king,\\nbeshrew them!\\nHe must be told on't, and he shall: the office\\nBecom\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrada:\\n\", texto_de_ids(lote_entrada_ejemplo[0]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "368146ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones próximo carácter:\n",
      " b\"QGAjCT-qwpdT.XtHw&d.JZw:ELChdzLNatNqU\\n$wticAuYe!dfTEL'NjVz$QL&&jeo\\nFj,uefs3,wrtTfGxJ?byw3qEtUGB!TnKD\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicciones próximo carácter:\\n\", texto_de_ids(indices_muestra).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f69da",
   "metadata": {},
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "Ahora tenemos un problema estandar de clasificación. Dado el estado previo del RNN, y la entrada en este paso, predice la clase del próximo carácter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aedee6",
   "metadata": {},
   "source": [
    "### Optimizador y función de pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55dbbb",
   "metadata": {},
   "source": [
    "Podemos usar `tf.keras.losses.sparse_categorical_crossentropy` ya que se aplica en la última dimensión de las predicciones.\n",
    "\n",
    "Ya que el modelo retorna *logits*, hay que especificar `from_logits=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf4b91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdida = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6719a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_lote_perdida_promedia = perdida(lote_objetivo_ejemplo, lote_predicciones_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93fc1ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma predicción:  (64, 100, 66) # (lote, secuencia, vocabulario)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma predicción: \", lote_predicciones_ejemplo.shape, \"# (lote, secuencia, vocabulario)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a472a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perdida promedia:  tf.Tensor(4.190913, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perdida promedia: \", ejemplo_lote_perdida_promedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f032a3",
   "metadata": {},
   "source": [
    "Un modelo recién inicializado no debería estar demasiado seguro de sus salidas. Podemos confirmar eso usando la exponencial de la perdida promedia, y verificando que es aproximadamente igual al tamaño del vocabulario. Una perdida mucho más grande indica que el modelo es muy seguro de sus respuestas incorrectas, y su inicialización es mala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "368f95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.08311"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(ejemplo_lote_perdida_promedia).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36b659",
   "metadata": {},
   "source": [
    "Compilamos el modelo (basicamente creando los grafos etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55b98c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss=perdida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f5520",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "\n",
    "Usamos *checkpoints* para guardar los parámetros durante el entrenamiento, por si acaso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd936e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30b18bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fed0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb31879",
   "metadata": {},
   "source": [
    "## Entrenar!\n",
    "\n",
    "Entrenamos el modelo para $10$ epocas, para tener un tiempo razonable... También podríamos usar GPU para acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6467be",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCAS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "519384a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:05:23.870207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-25 10:05:23.870634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115394]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-25 10:05:24.195407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 10:05:24.196925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 10:05:24.197972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-25 10:05:24.577382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-25 10:05:24.578497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-25 10:05:24.579684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 521s 3s/step - loss: 2.6929\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 455s 3s/step - loss: 1.9688\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 444s 3s/step - loss: 1.6921\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 441s 3s/step - loss: 1.5349\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 448s 3s/step - loss: 1.4392\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 435s 3s/step - loss: 1.3732\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 454s 3s/step - loss: 1.3216\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 454s 3s/step - loss: 1.2768\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 448s 3s/step - loss: 1.2365\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 448s 3s/step - loss: 1.1965\n"
     ]
    }
   ],
   "source": [
    "historia = modelo.fit(dataset, epochs=EPOCAS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a52ea",
   "metadata": {},
   "source": [
    "### Generar texto\n",
    "\n",
    "Podemos generar texto con el modelo usando un ciclo, con seguimiento del estado interno.\n",
    "\n",
    "![](text_generation_sampling.png)\n",
    "\n",
    "Cada vez que llamamos al modelo, pasamos texto y su estado interno. El modelo devuelve una predicción para el próximo carácter y su estado nuevo. Pasamos la predicción y el estado de nuevo al modelo para generar más texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "153ece74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnPaso(tf.keras.Model):\n",
    "    def __init__(self, modelo, cars_de_ids, ids_de_cars, temperatura=1.0):\n",
    "        super().__init__()\n",
    "        self.temperatura = temperatura\n",
    "        self.modelo = modelo\n",
    "        self.cars_de_ids = cars_de_ids\n",
    "        self.ids_de_cars = ids_de_cars\n",
    "        \n",
    "        # Crear una máscara para prevenir generación de \"[UNK]\"\n",
    "        #saltar_ids = self.ids_de_cars('[UNK]').numpy()\n",
    "        #mascara_escasa = tf.SparseTensor(\n",
    "            # Ponemos -inf en cada indice malo\n",
    "        #    values=-float('inf'),\n",
    "        #    indices=saltar_ids,\n",
    "            # igualar la forma al vocabulario\n",
    "        #    dense_shape=[len(ids_de_cars.get_vocabulary())])\n",
    "        #self.mascara_prediccion = tf.sparse.to_dense(mascara_escasa)\n",
    "        \n",
    "    @tf.function\n",
    "    def generar_un_paso(self, entradas, estados=None):\n",
    "        # Convertir strings a IDs de fichas\n",
    "        entrada_cars = tf.strings.unicode_split(entradas, 'UTF-8')\n",
    "        entrada_ids = self.ids_de_cars(entrada_cars).to_tensor()\n",
    "        \n",
    "        # Ejecutar el modelo\n",
    "        # logits_predichos.shape es [lote, carácteres, logits_próximo_carácter]\n",
    "        logits_predichos, estados = self.modelo(inputs=entrada_ids,\n",
    "                                                states=estados,\n",
    "                                                return_state=True)\n",
    "        # Ocupar solamente la última predicción\n",
    "        logits_predichos = logits_predichos[:, -1, :]\n",
    "        logits_predichos = logits_predichos/self.temperatura\n",
    "        # Aplicar la mascara de predicción para prevenir \"[UNK]\"\n",
    "        logits_predichos = logits_predichos #+ self.mascara_prediccion\n",
    "        \n",
    "        # Obtener muestra de los logits de salida para generar fichas de IDs\n",
    "        ids_predichas = tf.random.categorical(logits_predichos, num_samples=1)\n",
    "        ids_predichas = tf.squeeze(ids_predichas, axis=-1)\n",
    "        \n",
    "        # Convertir de fichas de ID a carácteres\n",
    "        cars_predichos = self.cars_de_ids(ids_predichas)\n",
    "        \n",
    "        # Retornar los carácteres y el estado del modelo\n",
    "        return cars_predichos, estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d48117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_paso_modelo = UnPaso(modelo, cars_de_ids, ids_de_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "989e08dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 13:55:22.873876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-26 13:55:22.874897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-26 13:55:22.875975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-26 13:55:23.279083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-26 13:55:23.280214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-26 13:55:23.281141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "comienzo = time.time()\n",
    "estados = None\n",
    "proximo_car = tf.constant(['ROMEO:'])\n",
    "resultado = [proximo_car]\n",
    "\n",
    "for n in range(1000):\n",
    "    proximo_car, estados = un_paso_modelo.generar_un_paso(proximo_car, estados=estados)\n",
    "    resultado.append(proximo_car)\n",
    "    \n",
    "resultado = tf.strings.join(resultado)\n",
    "final = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b02cc855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "That Roomey' but thy profit of him\n",
      "And city of him, put every hand.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Who had he shall not.\n",
      "Mard that the mercy should but here appear\n",
      "At palm and no't:\n",
      "See, all post gagerel, his country may\n",
      "In the sallignhest sent to-day.\n",
      "Within my spirit of a city out on his paples,\n",
      "Even so in the valians. Take me\n",
      "The one poor cliff may pray thee. Bod!\n",
      "\n",
      "MERENIUS:\n",
      "You have no out my lord;\n",
      "So hath made jow in any tame the sun.\n",
      "Alto some other in done, thy heart will tear,\n",
      "Dreamnedly shall 't. He going presently rescoiled him;\n",
      "And now he knows my reammission which our corvins\n",
      "That I may chatte; and do good pubull\n",
      "And seen to long wething hours made\n",
      "A gentleman in our own sovereing stand:\n",
      "Being sawns uppell'd, and so we must do\n",
      "And bring the sweetest squaring he hads aponet;\n",
      "And so it is right old Mariqay be you, till King Henry's right,\n",
      "Have dancing should to action in deft he usurp.\n",
      "\n",
      "KING RICHARD II:\n",
      "Go, A wife in tume of Ronoraft she!\n",
      "The contentios of the Duke of Plater natural,\n",
      "\n",
      "Ped \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Tiempo de ejecución: 2.4016079902648926\n"
     ]
    }
   ],
   "source": [
    "print(resultado[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nTiempo de ejecución:', final - comienzo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23249e9b",
   "metadata": {},
   "source": [
    "Se puede implementar el paso de entrenamiento directamente, usando `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "404c853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTraining(MiModelo):\n",
    "    @tf.function\n",
    "    def train_step(self, inputs):\n",
    "        inputs, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.loss(labels, predictions)\n",
    "        grads = tape.gradient(loss, modelo.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, modelo.trainable_variables))\n",
    "\n",
    "        return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa928728",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = CustomTraining(vocab_size=len(ids_de_cars.get_vocabulary()),\n",
    "                        embedding_dim=embedding_dim,\n",
    "                        rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a371faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "               loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7dae12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:41:13.429748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-17 15:41:13.431293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-17 15:41:13.432282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-17 15:41:13.846361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-17 15:41:13.847807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-17 15:41:13.848783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/172 [>.............................] - ETA: 7:54 - loss: 4.2275"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m modelo\u001b[38;5;241m.\u001b[39mfit(dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelo.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d577a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
